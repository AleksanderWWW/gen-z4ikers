{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ae940472-96ba-43d2-a908-5d7125923240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import xgboost\n",
    "import optuna\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc1518d8-d69d-4c46-bf46-9b88ef0e6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transactions = pd.read_json(\"../transactions.json\", lines=True)\n",
    "data_merchants = pd.read_csv(\"../merchants.csv\")\n",
    "data_users = pd.read_csv(\"../users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e87ba73d-901d-4c25-a569-1429825955af",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = pd.json_normalize(data_transactions['location'])\n",
    "location_df.columns = ['latitude', 'longitude']\n",
    "\n",
    "data_transactions = data_transactions.drop(columns=['location']).join(location_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "675d58cd-1731-4102-a3ba-4b856a76c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_transactions.merge(data_merchants, on='merchant_id', how='left').merge(data_users, on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1737cc8-c0e9-4669-8b3b-bfd83dc20aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education\n",
       "PhD             103760\n",
       "Master          100526\n",
       "Bachelor        100325\n",
       "High School      98823\n",
       "No Education     96566\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"education\"] = df[\"education\"].fillna(\"No Education\")  # nan -> wykształcenie niższe niż średnie\n",
    "df[\"education\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2be0e2da-3d51-4ef4-a10b-54cfbf03cd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = df.drop(columns = [\"transaction_id\", \"currency\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1976d873-d26b-40ac-b659-0ca6a9fe3428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by user_id and timestamp for user-based features\n",
    "df_cleaned = df_cleaned.sort_values(by=[\"user_id\", \"timestamp\"])\n",
    "df_cleaned = df_cleaned.reset_index(drop=True) # Ensure unique, sequential index\n",
    "\n",
    "# User fraud history\n",
    "df_cleaned['temp_cumulative_fraud'] = df_cleaned.groupby('user_id')['is_fraud'].cumsum()\n",
    "shifted_cumulative_fraud = df_cleaned.groupby('user_id')['temp_cumulative_fraud'].shift(1)\n",
    "df_cleaned['user_has_fraud_history'] = shifted_cumulative_fraud.fillna(0).gt(0).astype(int)\n",
    "df_cleaned = df_cleaned.drop(columns=['temp_cumulative_fraud'])\n",
    "\n",
    "# User transaction count\n",
    "df_cleaned[\"dummy\"] = np.ones(len(df_cleaned))\n",
    "df_cleaned[\"users_transaction_count\"] = df_cleaned.groupby(\"user_id\")[\"dummy\"].cumsum().astype(int)\n",
    "df_cleaned = df_cleaned.drop(columns=[\"dummy\"])\n",
    "\n",
    "# Time since last transaction for user\n",
    "df_cleaned['time_since_last_transaction_user'] = df_cleaned.groupby('user_id')['timestamp'].diff().dt.days\n",
    "df_cleaned['time_since_last_transaction_user'] = df_cleaned['time_since_last_transaction_user'].fillna(0).astype(int)\n",
    "\n",
    "# Transaction amount statistics for user\n",
    "user_amount_mean_shifted = df_cleaned.groupby('user_id')['amount'].transform(lambda x: x.expanding().mean().shift(1))\n",
    "user_amount_std_shifted = df_cleaned.groupby('user_id')['amount'].transform(lambda x: x.expanding().std().shift(1))\n",
    "df_cleaned['transaction_amount_std_from_user_mean'] = (df_cleaned['amount'] - user_amount_mean_shifted) / user_amount_std_shifted\n",
    "df_cleaned['transaction_amount_std_from_user_mean'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "df_cleaned['transaction_amount_std_from_user_mean'].fillna(0, inplace=True)\n",
    "\n",
    "# Days since signup\n",
    "df_cleaned['signup_date'] = pd.to_datetime(df_cleaned['signup_date'])\n",
    "df_cleaned['transaction_date'] = pd.to_datetime(df_cleaned['timestamp'], unit='ms')\n",
    "df_cleaned['days_since_signup'] = (df_cleaned['transaction_date'] - df_cleaned['signup_date']).dt.total_seconds() / (24*3600)\n",
    "\n",
    "# Transaction time features\n",
    "df_cleaned['transaction_hour'] = df_cleaned['transaction_date'].dt.hour\n",
    "df_cleaned['is_transaction_night'] = ((df_cleaned['transaction_hour'] >= 0) & (df_cleaned['transaction_hour'] < 6)).astype(int)\n",
    "\n",
    "# Helper function for rolling count\n",
    "def rolling_count(series, window):\n",
    "    # series is a DataFrame with 'transaction_date'\n",
    "    return series['transaction_date'].apply(\n",
    "        lambda x: ((series['transaction_date'] >= (x - pd.Timedelta(window))) & (series['transaction_date'] < x)).sum()\n",
    "    )\n",
    "\n",
    "# Calculate transactions in the last 1 hour for each user\n",
    "df_cleaned['transactions_last_1h_user'] = (\n",
    "    df_cleaned.groupby('user_id', group_keys=False)\n",
    "    .apply(lambda group: rolling_count(group, '1h'))\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# Calculate transactions in the last 24 hours for each user\n",
    "df_cleaned['transactions_last_24h_user'] = (\n",
    "    df_cleaned.groupby('user_id', group_keys=False)\n",
    "    .apply(lambda group: rolling_count(group, '24h'))\n",
    "    .sort_index()\n",
    ")\n",
    "\n",
    "# Average amount of last 5 transactions for user\n",
    "df_cleaned['avg_amount_last_5_tx_user'] = df_cleaned.groupby('user_id')['amount'].transform(lambda x: x.rolling(window=5, min_periods=1).mean().shift(1))\n",
    "df_cleaned['avg_amount_last_5_tx_user'].fillna(0, inplace=True)\n",
    "\n",
    "# Sort by merchant_id and timestamp for merchant-based features\n",
    "df_cleaned = df_cleaned.sort_values(by=[\"merchant_id\", \"timestamp\"])\n",
    "df_cleaned = df_cleaned.reset_index(drop=True) # Reset index again\n",
    "\n",
    "# Merchant fraud history\n",
    "df_cleaned['temp_cumulative_fraud'] = df_cleaned.groupby('merchant_id')['is_fraud'].cumsum()\n",
    "shifted_cumulative_fraud = df_cleaned.groupby('merchant_id')['temp_cumulative_fraud'].shift(1)\n",
    "df_cleaned['merchant_has_fraud_history'] = shifted_cumulative_fraud.fillna(0).gt(0).astype(int)\n",
    "df_cleaned = df_cleaned.drop(columns=['temp_cumulative_fraud'])\n",
    "\n",
    "df_cleaned = df_cleaned.sort_values(by=[\"user_id\", \"timestamp\"]) # Consistent sorting\n",
    "df_cleaned = df_cleaned.reset_index(drop=True) # Clean index\n",
    "\n",
    "def _get_user_device_mode_for_transform(series):\n",
    "    # Ensure numpy is imported in your notebook, e.g., import numpy as np\n",
    "    modes = series.mode()\n",
    "    if not modes.empty:\n",
    "        return modes.iloc[0]\n",
    "    return np.nan\n",
    "\n",
    "df_cleaned['user_mode_device_temp'] = df_cleaned.groupby('user_id')['device'].transform(_get_user_device_mode_for_transform)\n",
    "df_cleaned['device_changed'] = 0\n",
    "has_mode_device = df_cleaned['user_mode_device_temp'].notna()\n",
    "df_cleaned.loc[has_mode_device, 'device_changed'] = \\\n",
    "    (df_cleaned.loc[has_mode_device, 'device'] != df_cleaned.loc[has_mode_device, 'user_mode_device_temp']).astype(int)\n",
    "\n",
    "#Change datatypes if necessary\n",
    "df_cleaned['days_since_signup'] = df_cleaned['days_since_signup'].astype(int)\n",
    "\n",
    "# Clean up temporary columns\n",
    "df_features_added = df_cleaned.drop(columns=['transaction_date', 'signup_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1273bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the data with time-delta info\n",
    "df_features_added = df_cleaned.drop(columns=['transaction_date', 'signup_date', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "88df0c3f-027a-412e-a0ac-1f941087c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "X = df_features_added.drop(columns=[\"is_fraud\"])\n",
    "y = df_features_added[\"is_fraud\"]\n",
    "\n",
    "X = pd.DataFrame(enc.fit_transform(X), columns=X.columns)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "X_res, y_res = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037d690b",
   "metadata": {},
   "source": [
    "Tune the model a little bit before RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8feabf66-1e59-41f5-94c1-182b916e5f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 10:52:43,096] A new study created in memory with name: no-name-3abcd5b9-1447-44f4-a491-11468bc7f7be\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 10:52:44,252] Trial 0 finished with value: 0.558860328316766 and parameters: {'learning_rate': 0.07227045963478206, 'n_estimators': 62, 'max_depth': 7, 'subsample': 0.6010960394534356, 'colsample_bytree': 0.6988145770996592, 'gamma': 2.177620191620898}. Best is trial 0 with value: 0.558860328316766.\n",
      "[I 2025-05-16 10:52:47,525] Trial 1 finished with value: 0.5453156212405795 and parameters: {'learning_rate': 0.0685146203478071, 'n_estimators': 120, 'max_depth': 9, 'subsample': 0.7804130776105705, 'colsample_bytree': 0.9853961896454996, 'gamma': 1.9446417926065025}. Best is trial 0 with value: 0.558860328316766.\n",
      "[I 2025-05-16 10:52:49,892] Trial 2 finished with value: 0.5476989686479482 and parameters: {'learning_rate': 0.09557209285640683, 'n_estimators': 158, 'max_depth': 7, 'subsample': 0.8821037547382217, 'colsample_bytree': 0.7895869032355284, 'gamma': 0.8100014515515974}. Best is trial 0 with value: 0.558860328316766.\n",
      "[I 2025-05-16 10:52:51,394] Trial 3 finished with value: 0.5700998009088671 and parameters: {'learning_rate': 0.05519577167073518, 'n_estimators': 185, 'max_depth': 4, 'subsample': 0.8034449655467347, 'colsample_bytree': 0.6639193699483051, 'gamma': 1.809078479908719}. Best is trial 3 with value: 0.5700998009088671.\n",
      "[I 2025-05-16 10:52:53,220] Trial 4 finished with value: 0.5503844548016029 and parameters: {'learning_rate': 0.20060114172570354, 'n_estimators': 283, 'max_depth': 3, 'subsample': 0.7409815717046272, 'colsample_bytree': 0.9225619520231536, 'gamma': 1.975720973544438}. Best is trial 3 with value: 0.5700998009088671.\n",
      "[I 2025-05-16 10:52:54,109] Trial 5 finished with value: 0.5399874359431796 and parameters: {'learning_rate': 0.23321311014606616, 'n_estimators': 52, 'max_depth': 6, 'subsample': 0.6389091542484029, 'colsample_bytree': 0.7649332575503228, 'gamma': 0.36400808223753633}. Best is trial 3 with value: 0.5700998009088671.\n",
      "[I 2025-05-16 10:52:55,022] Trial 6 finished with value: 0.5676774509320103 and parameters: {'learning_rate': 0.12007287705264683, 'n_estimators': 134, 'max_depth': 2, 'subsample': 0.7754472355686172, 'colsample_bytree': 0.8232904460818739, 'gamma': 1.4015224742921966}. Best is trial 3 with value: 0.5700998009088671.\n",
      "[I 2025-05-16 10:52:57,242] Trial 7 finished with value: 0.5312625423354012 and parameters: {'learning_rate': 0.22857666604845814, 'n_estimators': 248, 'max_depth': 5, 'subsample': 0.7849236766294203, 'colsample_bytree': 0.7074877288896924, 'gamma': 1.4347740331794412}. Best is trial 3 with value: 0.5700998009088671.\n",
      "[I 2025-05-16 10:52:58,229] Trial 8 finished with value: 0.5566544376556144 and parameters: {'learning_rate': 0.2648469933326228, 'n_estimators': 155, 'max_depth': 2, 'subsample': 0.6130660491693393, 'colsample_bytree': 0.8640234280438206, 'gamma': 2.0851276569873614}. Best is trial 3 with value: 0.5700998009088671.\n",
      "[I 2025-05-16 10:53:00,089] Trial 9 finished with value: 0.5681782473457164 and parameters: {'learning_rate': 0.04909122783185828, 'n_estimators': 181, 'max_depth': 5, 'subsample': 0.7316874304815253, 'colsample_bytree': 0.7827935865383497, 'gamma': 2.6167399604934967}. Best is trial 3 with value: 0.5700998009088671.\n",
      "[I 2025-05-16 10:53:04,931] Trial 10 finished with value: 0.5718812931652122 and parameters: {'learning_rate': 0.014334954250657117, 'n_estimators': 207, 'max_depth': 10, 'subsample': 0.9879368589020441, 'colsample_bytree': 0.6054197492252908, 'gamma': 3.978916302918839}. Best is trial 10 with value: 0.5718812931652122.\n",
      "[I 2025-05-16 10:53:09,641] Trial 11 finished with value: 0.5719082442713576 and parameters: {'learning_rate': 0.01432116383456545, 'n_estimators': 216, 'max_depth': 10, 'subsample': 0.9859202507043119, 'colsample_bytree': 0.6161812999438628, 'gamma': 4.288799574117779}. Best is trial 11 with value: 0.5719082442713576.\n",
      "[I 2025-05-16 10:53:12,927] Trial 12 finished with value: 0.5732309479101628 and parameters: {'learning_rate': 0.024677362663877364, 'n_estimators': 225, 'max_depth': 10, 'subsample': 0.981216405707781, 'colsample_bytree': 0.6068282771673017, 'gamma': 4.4741253854200895}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:17,124] Trial 13 finished with value: 0.5728220252575031 and parameters: {'learning_rate': 0.010074508224276656, 'n_estimators': 238, 'max_depth': 9, 'subsample': 0.9914628678381884, 'colsample_bytree': 0.6093093878033019, 'gamma': 4.709452146394026}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:18,857] Trial 14 finished with value: 0.5623977620623305 and parameters: {'learning_rate': 0.1510809042955188, 'n_estimators': 297, 'max_depth': 8, 'subsample': 0.9215284105198629, 'colsample_bytree': 0.6536352236507234, 'gamma': 4.939987606223774}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:24,598] Trial 15 finished with value: 0.5714526433715045 and parameters: {'learning_rate': 0.010593743578271572, 'n_estimators': 247, 'max_depth': 9, 'subsample': 0.9242507870058366, 'colsample_bytree': 0.7105400418784134, 'gamma': 3.2965965279538603}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:26,499] Trial 16 finished with value: 0.5561359674766392 and parameters: {'learning_rate': 0.13836522820951302, 'n_estimators': 254, 'max_depth': 9, 'subsample': 0.8668898839935597, 'colsample_bytree': 0.6015655692000734, 'gamma': 4.758190334058434}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:28,171] Trial 17 finished with value: 0.560426904320838 and parameters: {'learning_rate': 0.1073085657948401, 'n_estimators': 220, 'max_depth': 8, 'subsample': 0.9445644112707146, 'colsample_bytree': 0.6582011603272734, 'gamma': 3.4076414555991437}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:29,976] Trial 18 finished with value: 0.5475643933437401 and parameters: {'learning_rate': 0.17276046104855003, 'n_estimators': 276, 'max_depth': 8, 'subsample': 0.8505937439082374, 'colsample_bytree': 0.7584397129598986, 'gamma': 3.9727268338017314}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:33,124] Trial 19 finished with value: 0.5633756416256163 and parameters: {'learning_rate': 0.043241576462888, 'n_estimators': 236, 'max_depth': 10, 'subsample': 0.9996197883999288, 'colsample_bytree': 0.8583712603601957, 'gamma': 3.082298120542257}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:34,254] Trial 20 finished with value: 0.5562613632208006 and parameters: {'learning_rate': 0.299585966368787, 'n_estimators': 198, 'max_depth': 7, 'subsample': 0.9541362428130167, 'colsample_bytree': 0.7286817056088956, 'gamma': 4.504413342735601}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:37,344] Trial 21 finished with value: 0.5705735442948549 and parameters: {'learning_rate': 0.028541393267544422, 'n_estimators': 212, 'max_depth': 10, 'subsample': 0.968067410106528, 'colsample_bytree': 0.6244920149379142, 'gamma': 4.286694587498879}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:39,543] Trial 22 finished with value: 0.5573033623330391 and parameters: {'learning_rate': 0.0781782927921375, 'n_estimators': 226, 'max_depth': 10, 'subsample': 0.8993538267412168, 'colsample_bytree': 0.6301184394767408, 'gamma': 3.8680143522773456}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:42,081] Trial 23 finished with value: 0.5727498313606548 and parameters: {'learning_rate': 0.03347534711158652, 'n_estimators': 269, 'max_depth': 9, 'subsample': 0.9980430453173816, 'colsample_bytree': 0.6761670164612349, 'gamma': 4.982547467435056}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:44,455] Trial 24 finished with value: 0.5701208911321339 and parameters: {'learning_rate': 0.038535175304626273, 'n_estimators': 267, 'max_depth': 9, 'subsample': 0.9431108190075201, 'colsample_bytree': 0.6778242109805088, 'gamma': 4.947810538928992}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:46,602] Trial 25 finished with value: 0.5532227080855283 and parameters: {'learning_rate': 0.09083393418118987, 'n_estimators': 265, 'max_depth': 8, 'subsample': 0.83142518985415, 'colsample_bytree': 0.6502105982491833, 'gamma': 3.5676790774858542}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:49,377] Trial 26 finished with value: 0.5684618247306793 and parameters: {'learning_rate': 0.03666009782495962, 'n_estimators': 290, 'max_depth': 9, 'subsample': 0.9082567306163062, 'colsample_bytree': 0.6843469102910539, 'gamma': 4.524694143241258}. Best is trial 12 with value: 0.5732309479101628.\n",
      "[I 2025-05-16 10:53:50,905] Trial 27 finished with value: 0.5749607682269945 and parameters: {'learning_rate': 0.06225274336620078, 'n_estimators': 234, 'max_depth': 6, 'subsample': 0.9725262870020678, 'colsample_bytree': 0.729999223316507, 'gamma': 4.67092391014463}. Best is trial 27 with value: 0.5749607682269945.\n",
      "[I 2025-05-16 10:53:52,678] Trial 28 finished with value: 0.5695579365998796 and parameters: {'learning_rate': 0.06224374417189613, 'n_estimators': 234, 'max_depth': 6, 'subsample': 0.9673315065513366, 'colsample_bytree': 0.7372089581378757, 'gamma': 2.783325877806382}. Best is trial 27 with value: 0.5749607682269945.\n",
      "[I 2025-05-16 10:53:54,867] Trial 29 finished with value: 0.5493299080304112 and parameters: {'learning_rate': 0.08201509805905995, 'n_estimators': 195, 'max_depth': 7, 'subsample': 0.6848784895077532, 'colsample_bytree': 0.8368491643024991, 'gamma': 3.681102532156588}. Best is trial 27 with value: 0.5749607682269945.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.06225274336620078, 'n_estimators': 234, 'max_depth': 6, 'subsample': 0.9725262870020678, 'colsample_bytree': 0.729999223316507, 'gamma': 4.67092391014463}\n",
      "Best F1: 0.5749607682269945\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"n_jobs\": -1,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"use_label_encoder\": False,\n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    f1 = cross_val_score(model, X_res, y_res, cv=cv, scoring=\"f1\").mean()\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best F1:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "26ef7453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE done: best F1=0.5803 with 3 features.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.base import clone\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def rfe_with_cv(\n",
    "    model_prototype,\n",
    "    X: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    n_splits: int = 5,\n",
    "    scoring = make_scorer(f1_score),\n",
    "    random_state = 42)\n",
    "    \n",
    "    # Initialization\n",
    "    features = X.columns.tolist()\n",
    "    best_score = -np.inf\n",
    "    best_features = features.copy()\n",
    "    f1_history = {}\n",
    "\n",
    "    # CV strategy\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=n_splits,\n",
    "        shuffle=True,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Iterative elimination\n",
    "    while features:\n",
    "        # Evaluate current feature set via cross-validation\n",
    "        model = clone(model_prototype)\n",
    "        scores = cross_val_score(\n",
    "            model,\n",
    "            X[features],\n",
    "            y,\n",
    "            cv=cv,\n",
    "            scoring=scoring,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        mean_score = np.mean(scores)\n",
    "        f1_history[len(features)] = mean_score\n",
    "\n",
    "        # Update best if improved (or same score with fewer features)\n",
    "        if mean_score > best_score or (\n",
    "            np.isclose(mean_score, best_score) and len(features) < len(best_features)\n",
    "        ):\n",
    "            best_score = mean_score\n",
    "            best_features = features.copy()\n",
    "\n",
    "        # Stop if only one feature remains\n",
    "        if len(features) == 1:\n",
    "            break\n",
    "\n",
    "        # Fit on the full data to get importances\n",
    "        model_full = clone(model_prototype)\n",
    "        model_full.fit(X[features], y)\n",
    "        importances = pd.Series(\n",
    "            model_full.feature_importances_,\n",
    "            index=features\n",
    "        )\n",
    "        # Eliminate least important feature\n",
    "        least_imp = importances.idxmin()\n",
    "        features.remove(least_imp)\n",
    "\n",
    "    print(\n",
    "        f\"RFE done: best F1={best_score:.4f} with {len(best_features)} features.\"\n",
    "    )\n",
    "    return best_features, f1_history\n",
    "\n",
    "\n",
    "best_params = {'learning_rate': 0.06225274336620078, 'n_estimators': 234, 'max_depth': 6, 'subsample': 0.9725262870020678, 'colsample_bytree': 0.729999223316507, 'gamma': 4.67092391014463}\n",
    "\n",
    "xgb_prototype = XGBClassifier(**best_params)\n",
    "best_feats, history = rfe_with_cv(xgb_prototype, X_res, y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdc6b24",
   "metadata": {},
   "source": [
    "Now with reduce feature size lets run Optuna with Stratified KFold again to tune the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a9bafe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 11:15:58,589] A new study created in memory with name: no-name-5428b7fc-0085-4859-b08f-3d79d41bfbfc\n",
      "[I 2025-05-16 11:15:59,832] Trial 0 finished with value: 0.5660964267408339 and parameters: {'learning_rate': 0.26543829344784864, 'n_estimators': 51, 'max_depth': 7, 'subsample': 0.7540771246706623, 'colsample_bytree': 0.6942341244688814, 'gamma': 0.21464636716703733}. Best is trial 0 with value: 0.5660964267408339.\n",
      "[I 2025-05-16 11:16:00,865] Trial 1 finished with value: 0.5630070580831936 and parameters: {'learning_rate': 0.27749505594991913, 'n_estimators': 82, 'max_depth': 8, 'subsample': 0.6690453682061623, 'colsample_bytree': 0.6220747726601121, 'gamma': 3.2451311943346846}. Best is trial 0 with value: 0.5660964267408339.\n",
      "[I 2025-05-16 11:16:02,550] Trial 2 finished with value: 0.5686258958921353 and parameters: {'learning_rate': 0.03412470973210163, 'n_estimators': 84, 'max_depth': 7, 'subsample': 0.7019462210654983, 'colsample_bytree': 0.7824627593606372, 'gamma': 0.5180140060444166}. Best is trial 2 with value: 0.5686258958921353.\n",
      "[I 2025-05-16 11:16:03,817] Trial 3 finished with value: 0.5756869353036687 and parameters: {'learning_rate': 0.2219363103480137, 'n_estimators': 113, 'max_depth': 9, 'subsample': 0.8917105686423366, 'colsample_bytree': 0.9492194510432184, 'gamma': 3.3088308658032877}. Best is trial 3 with value: 0.5756869353036687.\n",
      "[I 2025-05-16 11:16:05,753] Trial 4 finished with value: 0.5767229057354158 and parameters: {'learning_rate': 0.25998597325441997, 'n_estimators': 205, 'max_depth': 3, 'subsample': 0.7598103528948408, 'colsample_bytree': 0.8081107538173385, 'gamma': 4.477686424295948}. Best is trial 4 with value: 0.5767229057354158.\n",
      "[I 2025-05-16 11:16:06,902] Trial 5 finished with value: 0.5666423437371345 and parameters: {'learning_rate': 0.11090272620375465, 'n_estimators': 51, 'max_depth': 7, 'subsample': 0.616070175335159, 'colsample_bytree': 0.8889697762361561, 'gamma': 0.1855711647362629}. Best is trial 4 with value: 0.5767229057354158.\n",
      "[I 2025-05-16 11:16:09,282] Trial 6 finished with value: 0.5661836189775807 and parameters: {'learning_rate': 0.051684070209155546, 'n_estimators': 130, 'max_depth': 6, 'subsample': 0.6017543045934968, 'colsample_bytree': 0.8459155801158633, 'gamma': 0.17888697808880472}. Best is trial 4 with value: 0.5767229057354158.\n",
      "[I 2025-05-16 11:16:11,102] Trial 7 finished with value: 0.5732394281330284 and parameters: {'learning_rate': 0.27209963575582174, 'n_estimators': 162, 'max_depth': 5, 'subsample': 0.8089654349641188, 'colsample_bytree': 0.9659515458969627, 'gamma': 2.2406730881164405}. Best is trial 4 with value: 0.5767229057354158.\n",
      "[I 2025-05-16 11:16:12,986] Trial 8 finished with value: 0.5769950761211029 and parameters: {'learning_rate': 0.24666727788342174, 'n_estimators': 171, 'max_depth': 8, 'subsample': 0.7754721079860081, 'colsample_bytree': 0.6872336009865414, 'gamma': 3.789875087898417}. Best is trial 8 with value: 0.5769950761211029.\n",
      "[I 2025-05-16 11:16:14,012] Trial 9 finished with value: 0.5756510261224773 and parameters: {'learning_rate': 0.12984017854992502, 'n_estimators': 54, 'max_depth': 7, 'subsample': 0.8131229158094236, 'colsample_bytree': 0.7051320470894575, 'gamma': 2.0045399417168723}. Best is trial 8 with value: 0.5769950761211029.\n",
      "[I 2025-05-16 11:16:16,685] Trial 10 finished with value: 0.5602965183970635 and parameters: {'learning_rate': 0.19966529843437164, 'n_estimators': 289, 'max_depth': 10, 'subsample': 0.9877678105483979, 'colsample_bytree': 0.6001076320694338, 'gamma': 4.890624224746635}. Best is trial 8 with value: 0.5769950761211029.\n",
      "[I 2025-05-16 11:16:19,115] Trial 11 finished with value: 0.5780405512862334 and parameters: {'learning_rate': 0.20514792807790727, 'n_estimators': 219, 'max_depth': 2, 'subsample': 0.8722182914093871, 'colsample_bytree': 0.7679077923274663, 'gamma': 4.96536951351638}. Best is trial 11 with value: 0.5780405512862334.\n",
      "[I 2025-05-16 11:16:21,218] Trial 12 finished with value: 0.5781565182109307 and parameters: {'learning_rate': 0.20324677785913303, 'n_estimators': 228, 'max_depth': 2, 'subsample': 0.872564192911363, 'colsample_bytree': 0.7324102037369982, 'gamma': 3.9552147136418094}. Best is trial 12 with value: 0.5781565182109307.\n",
      "[I 2025-05-16 11:16:23,395] Trial 13 finished with value: 0.5783241251164083 and parameters: {'learning_rate': 0.18943008906594552, 'n_estimators': 234, 'max_depth': 2, 'subsample': 0.8928654232783914, 'colsample_bytree': 0.7471703550687723, 'gamma': 4.205470590368242}. Best is trial 13 with value: 0.5783241251164083.\n",
      "[I 2025-05-16 11:16:26,121] Trial 14 finished with value: 0.5781839583458263 and parameters: {'learning_rate': 0.16097484941389942, 'n_estimators': 263, 'max_depth': 4, 'subsample': 0.9412977604641819, 'colsample_bytree': 0.752429994582388, 'gamma': 3.9786450844901724}. Best is trial 13 with value: 0.5783241251164083.\n",
      "[I 2025-05-16 11:16:28,425] Trial 15 finished with value: 0.5782449501513643 and parameters: {'learning_rate': 0.15598572027417473, 'n_estimators': 278, 'max_depth': 4, 'subsample': 0.9754035804062198, 'colsample_bytree': 0.8477656387910475, 'gamma': 2.8654886675654936}. Best is trial 13 with value: 0.5783241251164083.\n",
      "[I 2025-05-16 11:16:30,670] Trial 16 finished with value: 0.5802858018175461 and parameters: {'learning_rate': 0.08064987168101993, 'n_estimators': 260, 'max_depth': 4, 'subsample': 0.9937915395146665, 'colsample_bytree': 0.8892121624525293, 'gamma': 2.807419318722784}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:32,907] Trial 17 finished with value: 0.5778210920146638 and parameters: {'learning_rate': 0.10499972559009535, 'n_estimators': 248, 'max_depth': 3, 'subsample': 0.9219693982229625, 'colsample_bytree': 0.9115316328220876, 'gamma': 1.5409005550955084}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:34,778] Trial 18 finished with value: 0.5793432134889279 and parameters: {'learning_rate': 0.07250830621749596, 'n_estimators': 194, 'max_depth': 4, 'subsample': 0.9981634541143205, 'colsample_bytree': 0.9957897882233253, 'gamma': 1.267895562142852}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:36,764] Trial 19 finished with value: 0.5751743178225303 and parameters: {'learning_rate': 0.080310180495508, 'n_estimators': 196, 'max_depth': 5, 'subsample': 0.9501948246878743, 'colsample_bytree': 0.9954866855994489, 'gamma': 0.9880644385485065}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:38,946] Trial 20 finished with value: 0.5763687010585635 and parameters: {'learning_rate': 0.011456987675177506, 'n_estimators': 149, 'max_depth': 5, 'subsample': 0.9995831501364608, 'colsample_bytree': 0.9121326965192988, 'gamma': 1.472374774723115}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:41,154] Trial 21 finished with value: 0.5789674966885138 and parameters: {'learning_rate': 0.06305643239316924, 'n_estimators': 246, 'max_depth': 3, 'subsample': 0.9106212883778262, 'colsample_bytree': 0.832612342618761, 'gamma': 2.6459142286841377}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:42,988] Trial 22 finished with value: 0.5786494842502855 and parameters: {'learning_rate': 0.069698095236281, 'n_estimators': 191, 'max_depth': 4, 'subsample': 0.945073508816298, 'colsample_bytree': 0.839300614148021, 'gamma': 2.5741471152837296}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:45,253] Trial 23 finished with value: 0.5776293100724289 and parameters: {'learning_rate': 0.08475631182542616, 'n_estimators': 252, 'max_depth': 3, 'subsample': 0.8369832630654777, 'colsample_bytree': 0.8796667443149883, 'gamma': 1.8428076716912463}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:47,963] Trial 24 finished with value: 0.5798817081330474 and parameters: {'learning_rate': 0.037173650785952334, 'n_estimators': 294, 'max_depth': 4, 'subsample': 0.9745779201437409, 'colsample_bytree': 0.9429909565508284, 'gamma': 2.774315395170899}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:50,693] Trial 25 finished with value: 0.5798018122739117 and parameters: {'learning_rate': 0.03523803378597431, 'n_estimators': 299, 'max_depth': 4, 'subsample': 0.9710068583980684, 'colsample_bytree': 0.9942366303364549, 'gamma': 3.171099039866938}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:53,958] Trial 26 finished with value: 0.5794492354984275 and parameters: {'learning_rate': 0.029211561050621244, 'n_estimators': 300, 'max_depth': 6, 'subsample': 0.9652924444449604, 'colsample_bytree': 0.9559440856543056, 'gamma': 3.1740281016573872}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:16:57,189] Trial 27 finished with value: 0.579392300810349 and parameters: {'learning_rate': 0.01283356094508192, 'n_estimators': 271, 'max_depth': 5, 'subsample': 0.9255597073201464, 'colsample_bytree': 0.9301991739492204, 'gamma': 3.5660565723386104}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:00,031] Trial 28 finished with value: 0.5785669040609547 and parameters: {'learning_rate': 0.0363220682612917, 'n_estimators': 297, 'max_depth': 6, 'subsample': 0.8405115954218016, 'colsample_bytree': 0.8832668453100364, 'gamma': 2.9788331904079772}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:02,408] Trial 29 finished with value: 0.5785382220642095 and parameters: {'learning_rate': 0.10297489163703619, 'n_estimators': 281, 'max_depth': 4, 'subsample': 0.9625530452908608, 'colsample_bytree': 0.9739415541748624, 'gamma': 2.2115056663456834}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:04,887] Trial 30 finished with value: 0.5784436203336897 and parameters: {'learning_rate': 0.04634576848468419, 'n_estimators': 267, 'max_depth': 3, 'subsample': 0.7248102113404078, 'colsample_bytree': 0.9309706840725787, 'gamma': 3.544832421990868}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:07,978] Trial 31 finished with value: 0.5795422008160138 and parameters: {'learning_rate': 0.025441936721041135, 'n_estimators': 295, 'max_depth': 6, 'subsample': 0.9735410582716779, 'colsample_bytree': 0.9658154900362931, 'gamma': 3.0215986410423334}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:10,236] Trial 32 finished with value: 0.5746299066608165 and parameters: {'learning_rate': 0.29876415961922836, 'n_estimators': 286, 'max_depth': 6, 'subsample': 0.9749095333282937, 'colsample_bytree': 0.9745849497301395, 'gamma': 2.8096077802153485}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:13,203] Trial 33 finished with value: 0.5785611418450067 and parameters: {'learning_rate': 0.02296641353734761, 'n_estimators': 262, 'max_depth': 5, 'subsample': 0.9323794522100642, 'colsample_bytree': 0.9299030550214166, 'gamma': 2.370186580648339}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:15,804] Trial 34 finished with value: 0.579219058505753 and parameters: {'learning_rate': 0.0530175918088591, 'n_estimators': 294, 'max_depth': 4, 'subsample': 0.9055892993465456, 'colsample_bytree': 0.9948328969163482, 'gamma': 3.2183066195911842}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:18,553] Trial 35 finished with value: 0.5796622152101534 and parameters: {'learning_rate': 0.037789477982604444, 'n_estimators': 300, 'max_depth': 8, 'subsample': 0.9620871952788622, 'colsample_bytree': 0.9415325689063628, 'gamma': 3.490710745999257}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:21,095] Trial 36 finished with value: 0.5779037630805967 and parameters: {'learning_rate': 0.09160318125454832, 'n_estimators': 277, 'max_depth': 8, 'subsample': 0.87375624836932, 'colsample_bytree': 0.905184233645385, 'gamma': 3.484455692077453}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:23,287] Trial 37 finished with value: 0.5769510914175157 and parameters: {'learning_rate': 0.12256168101349169, 'n_estimators': 256, 'max_depth': 9, 'subsample': 0.951428071686462, 'colsample_bytree': 0.9360349321652282, 'gamma': 2.502344458775313}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:25,298] Trial 38 finished with value: 0.5792756325329124 and parameters: {'learning_rate': 0.04815377563060242, 'n_estimators': 212, 'max_depth': 10, 'subsample': 0.9914125784497299, 'colsample_bytree': 0.8656990286250225, 'gamma': 4.390407418414958}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:27,731] Trial 39 finished with value: 0.5784575716103744 and parameters: {'learning_rate': 0.0628810658726334, 'n_estimators': 243, 'max_depth': 8, 'subsample': 0.9010441008321233, 'colsample_bytree': 0.8056101488023899, 'gamma': 3.37944988919383}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:30,134] Trial 40 finished with value: 0.5766568457970898 and parameters: {'learning_rate': 0.13424616295379785, 'n_estimators': 282, 'max_depth': 7, 'subsample': 0.71858027259783, 'colsample_bytree': 0.9496075471084486, 'gamma': 3.7878709522050853}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:33,160] Trial 41 finished with value: 0.578169223762418 and parameters: {'learning_rate': 0.032421330623096906, 'n_estimators': 295, 'max_depth': 9, 'subsample': 0.660606182121012, 'colsample_bytree': 0.9781254996201653, 'gamma': 2.9727210882754567}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:36,270] Trial 42 finished with value: 0.5799528731038961 and parameters: {'learning_rate': 0.021268433688570322, 'n_estimators': 300, 'max_depth': 5, 'subsample': 0.9743140958405342, 'colsample_bytree': 0.9477863563687678, 'gamma': 3.1168980480377377}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:38,871] Trial 43 finished with value: 0.5789767241922368 and parameters: {'learning_rate': 0.04236677669270589, 'n_estimators': 273, 'max_depth': 5, 'subsample': 0.9602634176983621, 'colsample_bytree': 0.9046350377609866, 'gamma': 2.0677368361148982}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:40,591] Trial 44 finished with value: 0.5763995714210057 and parameters: {'learning_rate': 0.011135360354315556, 'n_estimators': 118, 'max_depth': 4, 'subsample': 0.9789469089756826, 'colsample_bytree': 0.9465960541477728, 'gamma': 2.769940318298466}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:43,177] Trial 45 finished with value: 0.564113588512842 and parameters: {'learning_rate': 0.05751207747622166, 'n_estimators': 299, 'max_depth': 5, 'subsample': 0.9248274698726532, 'colsample_bytree': 0.6515184767931513, 'gamma': 3.664474069335146}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:44,338] Trial 46 finished with value: 0.5799675423304061 and parameters: {'learning_rate': 0.03970447773100759, 'n_estimators': 87, 'max_depth': 3, 'subsample': 0.9983111442578437, 'colsample_bytree': 0.8692122797590514, 'gamma': 3.2438239727984235}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:45,402] Trial 47 finished with value: 0.5763189690338211 and parameters: {'learning_rate': 0.02353161045254167, 'n_estimators': 63, 'max_depth': 3, 'subsample': 0.7860028746382245, 'colsample_bytree': 0.8588796758829165, 'gamma': 3.154520295891081}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:46,923] Trial 48 finished with value: 0.5792651091175152 and parameters: {'learning_rate': 0.09054033665167796, 'n_estimators': 101, 'max_depth': 2, 'subsample': 0.9862547525462232, 'colsample_bytree': 0.8245624694311129, 'gamma': 3.932300414684096}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:48,824] Trial 49 finished with value: 0.5801338569446799 and parameters: {'learning_rate': 0.07264077038225678, 'n_estimators': 136, 'max_depth': 3, 'subsample': 0.9974022946808194, 'colsample_bytree': 0.7882942294645123, 'gamma': 2.658621567263558}. Best is trial 16 with value: 0.5802858018175461.\n",
      "[I 2025-05-16 11:17:50,270] Trial 50 finished with value: 0.5808289801114086 and parameters: {'learning_rate': 0.07466160758595378, 'n_estimators': 139, 'max_depth': 2, 'subsample': 0.9972492496565205, 'colsample_bytree': 0.816503405915622, 'gamma': 1.7388660629903723}. Best is trial 50 with value: 0.5808289801114086.\n",
      "[I 2025-05-16 11:17:51,669] Trial 51 finished with value: 0.5807969022941301 and parameters: {'learning_rate': 0.0771899158213048, 'n_estimators': 140, 'max_depth': 2, 'subsample': 0.9889528922012416, 'colsample_bytree': 0.7896308615863223, 'gamma': 2.3125967677892434}. Best is trial 50 with value: 0.5808289801114086.\n",
      "[I 2025-05-16 11:17:53,093] Trial 52 finished with value: 0.5808732252825461 and parameters: {'learning_rate': 0.0783977100006569, 'n_estimators': 144, 'max_depth': 2, 'subsample': 0.9968671932668101, 'colsample_bytree': 0.7824185455643041, 'gamma': 1.7869281747876058}. Best is trial 52 with value: 0.5808732252825461.\n",
      "[I 2025-05-16 11:17:54,452] Trial 53 finished with value: 0.57954260170702 and parameters: {'learning_rate': 0.1191836394757178, 'n_estimators': 143, 'max_depth': 2, 'subsample': 0.9984861025369807, 'colsample_bytree': 0.7871359272912178, 'gamma': 1.908288872944512}. Best is trial 52 with value: 0.5808732252825461.\n",
      "[I 2025-05-16 11:17:56,079] Trial 54 finished with value: 0.5793105178428164 and parameters: {'learning_rate': 0.07533015326858762, 'n_estimators': 164, 'max_depth': 2, 'subsample': 0.9993513808320714, 'colsample_bytree': 0.785277062137157, 'gamma': 0.622210365936638}. Best is trial 52 with value: 0.5808732252825461.\n",
      "[I 2025-05-16 11:17:57,599] Trial 55 finished with value: 0.5782600374939357 and parameters: {'learning_rate': 0.10199392205421517, 'n_estimators': 134, 'max_depth': 3, 'subsample': 0.9492797589909256, 'colsample_bytree': 0.8198791741066, 'gamma': 1.7537127314015721}. Best is trial 52 with value: 0.5808732252825461.\n",
      "[I 2025-05-16 11:17:58,894] Trial 56 finished with value: 0.5795817542037527 and parameters: {'learning_rate': 0.09489725387967164, 'n_estimators': 101, 'max_depth': 2, 'subsample': 0.9864511382931959, 'colsample_bytree': 0.7639562642470209, 'gamma': 2.287958949522804}. Best is trial 52 with value: 0.5808732252825461.\n",
      "[I 2025-05-16 11:18:00,853] Trial 57 finished with value: 0.5769995193095527 and parameters: {'learning_rate': 0.14227859392606562, 'n_estimators': 182, 'max_depth': 3, 'subsample': 0.9426879186370317, 'colsample_bytree': 0.7256908228452049, 'gamma': 1.1421890432689032}. Best is trial 52 with value: 0.5808732252825461.\n",
      "[I 2025-05-16 11:18:02,490] Trial 58 finished with value: 0.5795641570682634 and parameters: {'learning_rate': 0.18027340715635193, 'n_estimators': 152, 'max_depth': 2, 'subsample': 0.9363487227097367, 'colsample_bytree': 0.8023097979210686, 'gamma': 1.6521375665445115}. Best is trial 52 with value: 0.5808732252825461.\n",
      "[I 2025-05-16 11:18:03,894] Trial 59 finished with value: 0.5798168825569164 and parameters: {'learning_rate': 0.08080218446973363, 'n_estimators': 126, 'max_depth': 2, 'subsample': 0.9832018454551434, 'colsample_bytree': 0.816789444590365, 'gamma': 2.0813940952713392}. Best is trial 52 with value: 0.5808732252825461.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'learning_rate': 0.0783977100006569, 'n_estimators': 144, 'max_depth': 2, 'subsample': 0.9968671932668101, 'colsample_bytree': 0.7824185455643041, 'gamma': 1.7869281747876058}\n",
      "Best F1: 0.5808732252825461\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Use only the RFE-selected features\n",
    "X_rfe = X_res[best_feats]\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"n_jobs\": -1,\n",
    "        \"eval_metric\": \"logloss\",\n",
    "        \"use_label_encoder\": False,\n",
    "    }\n",
    "    model = XGBClassifier(**params)\n",
    "    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    f1 = cross_val_score(model, X_rfe, y_res, cv=cv, scoring=\"f1\").mean()\n",
    "    return f1\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=60)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best F1:\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d315893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_model = XGBClassifier(**study.best_params)\n",
    "final_model.fit(X_res[best_feats], y_res)\n",
    "\n",
    "importances = pd.Series(final_model.feature_importances_, index=best_feats)\n",
    "importances.sort_values().plot(kind='barh', figsize=(6,8))\n",
    "plt.title(\"XGBoost Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Forecasting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
